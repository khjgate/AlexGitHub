# ë‰´ìŠ¤ë ˆí„° ìë™ ë°œì†¡ í”„ë¡œê·¸ë¨
# ì£¼ìš” IT ë‰´ìŠ¤ ìˆ˜ì§‘, HTML ë³¸ë¬¸ ìƒì„±, ì´ë©”ì¼ ë°œì†¡ ê¸°ëŠ¥ í¬í•¨
# ì£¼ì„ì€ í•œêµ­ì–´ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤


# ì´ë©”ì¼ í—¤ë” í•œê¸€ ì¸ì½”ë”©ì„ ìœ„í•œ Header ì¶”ê°€
# ì›¹ë¸Œë¼ìš°ì € ìë™ ì˜¤í”ˆì„ ìœ„í•œ ëª¨ë“ˆ ì¶”ê°€
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.image import MIMEImage
from email.header import Header
import datetime
import webbrowser
import os
import base64
import hashlib
# ì›¹ í¬ë¡¤ë§ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import requests
from bs4 import BeautifulSoup
import json

# ============================================================
# GitHub ì„¤ì • (GitHub Pages ìë™ ì—…ë¡œë“œìš©)
# í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê±°ë‚˜, ë¡œì»¬ ì‹¤í–‰ ì‹œ config íŒŒì¼ì—ì„œ ì½ìŒ (ì•”í˜¸í™”ëœ ê°’ ë³µí˜¸í™”)
# ============================================================
def decrypt_value(encoded_value):
    """base64ë¡œ ì•”í˜¸í™”ëœ ê°’ì„ ë³µí˜¸í™”"""
    try:
        return base64.b64decode(encoded_value).decode('utf-8')
    except:
        return encoded_value

def get_config_value(key):
    """í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” config íŒŒì¼ì—ì„œ ì„¤ì •ê°’ ì½ê¸° (ì•”í˜¸í™”ëœ ê°’ ìë™ ë³µí˜¸í™”)"""
    # í™˜ê²½ë³€ìˆ˜ ìš°ì„  (GitHub Actionsìš© - ì•”í˜¸í™”ë˜ì§€ ì•Šì€ ê°’)
    value = os.environ.get(key)
    if value:
        return value
    # ë¡œì»¬ config íŒŒì¼ì—ì„œ ì½ê¸° (ì•”í˜¸í™”ëœ ê°’)
    config_path = os.path.join(os.path.dirname(__file__), 'config.txt')
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                # ì•”í˜¸í™”ëœ í‚¤ (_ENC ì ‘ë¯¸ì‚¬) í™•ì¸
                enc_key = f'{key}_ENC='
                if line.startswith(enc_key):
                    encrypted_value = line.split('=', 1)[1]
                    return decrypt_value(encrypted_value)
    return ''

GITHUB_TOKEN = get_config_value('GITHUB_TOKEN')
GITHUB_REPO = 'khjgate/AlexGitHub'  # GitHub ë ˆí¬ì§€í† ë¦¬ (ì†Œìœ ì/ë ˆí¬ëª…)
GITHUB_BRANCH = 'main'  # ë¸Œëœì¹˜ëª…
GITHUB_PAGES_URL = 'https://khjgate.github.io/AlexGitHub'  # GitHub Pages URL


def upload_to_github(file_content, file_name):
    """
    GitHub APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ë ˆí¬ì§€í† ë¦¬ì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    """
    url = f'https://api.github.com/repos/{GITHUB_REPO}/contents/{file_name}'
    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json'
    }
    
    # íŒŒì¼ ë‚´ìš©ì„ base64ë¡œ ì¸ì½”ë”©
    content_base64 = base64.b64encode(file_content.encode('utf-8')).decode('utf-8')
    
    # ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸ (SHA ê°’ í•„ìš”)
    sha = None
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            sha = response.json().get('sha')
    except:
        pass
    
    # ì—…ë¡œë“œ ë°ì´í„° êµ¬ì„±
    data = {
        'message': f'Update {file_name} - {datetime.datetime.now().strftime("%Y-%m-%d %H:%M")}',
        'content': content_base64,
        'branch': GITHUB_BRANCH
    }
    
    # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ SHA ì¶”ê°€ (ì—…ë°ì´íŠ¸ìš©)
    if sha:
        data['sha'] = sha
    
    # GitHub APIë¡œ íŒŒì¼ ì—…ë¡œë“œ/ì—…ë°ì´íŠ¸
    log_path = os.path.join(os.path.dirname(__file__), 'github_upload_log.txt')
    def log_print(msg):
        print(msg)
        with open(log_path, 'a', encoding='utf-8') as f:
            f.write(msg + '\n')
    try:
        response = requests.put(url, headers=headers, json=data)
        if response.status_code in [200, 201]:
            log_print(f'âœ… GitHub ì—…ë¡œë“œ ì„±ê³µ: {file_name}')
            return True
        else:
            log_print(f'âŒ GitHub ì—…ë¡œë“œ ì‹¤íŒ¨: {response.status_code} - {response.text}')
            return False
    except Exception as e:
        log_print(f'âŒ GitHub ì—…ë¡œë“œ ì˜¤ë¥˜: {e}')
        return False


# 1. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ (êµ¬ê¸€ ë‰´ìŠ¤ RSS í™œìš©)
def collect_news():
    # êµ¬ê¸€ ë‰´ìŠ¤ RSSë¥¼ ì´ìš©í•˜ì—¬ ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘
    # ì „ì£¼ ì›”ìš”ì¼~ì¼ìš”ì¼ ì‚¬ì´ì˜ ë‰´ìŠ¤ ìš°ì„ , ë¶€ì¡±í•˜ë©´ 2ì£¼/3ì£¼ê¹Œì§€ í™•ëŒ€
    import urllib.parse
    import warnings
    # êµ¬ê¸€ ë‰´ìŠ¤ RSSë¥¼ ì´ìš©í•˜ì—¬ ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘
    # ì „ì£¼ ì›”ìš”ì¼~ì¼ìš”ì¼ ì‚¬ì´ì˜ ë‰´ìŠ¤ ìš°ì„ , ë¶€ì¡±í•˜ë©´ 2ì£¼/3ì£¼ê¹Œì§€ í™•ëŒ€
    import urllib.parse
    import warnings
    import re
    from datetime import datetime, timedelta
    from email.utils import parsedate_to_datetime
    warnings.filterwarnings('ignore')  # SSL ê²½ê³  ë¬´ì‹œ
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    # ë‚ ì§œ ë²”ìœ„ ê³„ì‚° í•¨ìˆ˜ (weeks_ago: 1=ì „ì£¼, 2=2ì£¼ì „, 3=3ì£¼ì „, 4=4ì£¼ì „)
    today = datetime.now()
    this_monday = today - timedelta(days=today.weekday())

    def get_week_range(weeks_ago):
        """weeks_ago ì£¼ ì „ì˜ ì›”~ì¼ ë‚ ì§œ ë²”ìœ„ ë°˜í™˜"""
        week_monday = this_monday - timedelta(days=7 * weeks_ago)
        week_sunday = week_monday + timedelta(days=6)
        start = week_monday.replace(hour=0, minute=0, second=0)
        end = week_sunday.replace(hour=23, minute=59, second=59)
        return start, end

    # 1ì£¼~4ì£¼ ì „ ë‚ ì§œ ë²”ìœ„ ë¯¸ë¦¬ ê³„ì‚°
    week_ranges = {
        1: get_week_range(1),  # ì „ì£¼
        2: get_week_range(2),  # 2ì£¼ ì „
        3: get_week_range(3),  # 3ì£¼ ì „
        4: get_week_range(4),  # 4ì£¼ ì „
    }

    print(f'ğŸ“… ë‰´ìŠ¤ ìˆ˜ì§‘ ê¸°ê°„: 1ì£¼ì „({week_ranges[1][0].strftime("%m/%d")}~{week_ranges[1][1].strftime("%m/%d")}) â†’ 2ì£¼ì „ â†’ 3ì£¼ì „ â†’ 4ì£¼ì „ ìˆœìœ¼ë¡œ í™•ëŒ€')
    # í”„ë¡¬í”„íŠ¸/ì¡°íšŒì¡°ê±´ì„ ë³„ë„ íŒŒì¼ì—ì„œ import
    from newsletter_prompt import trusted_sources, trusted_academic_sources, categories
    # ë‚ ì§œ íŒŒì‹± í•¨ìˆ˜
    def parse_pub_date(pub_date_str):
        """RSS pubDateë¥¼ datetimeìœ¼ë¡œ íŒŒì‹±"""
        try:
            return parsedate_to_datetime(pub_date_str)
        except:
            return None
    
    # ë‚ ì§œê°€ íŠ¹ì • ì£¼ ë²”ìœ„ ë‚´ì¸ì§€ í™•ì¸í•˜ê³  ëª‡ ì£¼ ì „ì¸ì§€ ë°˜í™˜
    def get_week_ago(pub_date_str):
        """ë‚ ì§œê°€ ëª‡ ì£¼ ì „ì¸ì§€ ë°˜í™˜ (1, 2, 3 ë˜ëŠ” None)"""
        pub_date = parse_pub_date(pub_date_str)
        if pub_date:
            pub_date_naive = pub_date.replace(tzinfo=None)
            for weeks_ago in [1, 2, 3, 4]:
                start, end = week_ranges[weeks_ago]
                if start <= pub_date_naive <= end:
                    return weeks_ago
        return None
    
    # ë‚ ì§œ í¬ë§· í•¨ìˆ˜ (ëª‡ ì£¼ ì „ì¸ì§€ í¬í•¨)
    def format_date_with_week(pub_date_str, weeks_ago):
        pub_date = parse_pub_date(pub_date_str)
        if pub_date:
            date_str = pub_date.strftime('%m/%d')
            if weeks_ago == 1:
                return date_str  # ì „ì£¼ëŠ” ë‚ ì§œë§Œ
            elif weeks_ago == 2:
                return f"{date_str} ğŸ•2ì£¼ì „"
            elif weeks_ago == 3:
                return f"{date_str} ğŸ•3ì£¼ì „"
        return ''
    
    # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ì œëª© ì •ê·œí™” í•¨ìˆ˜
    def normalize_title(title):
        # íŠ¹ìˆ˜ë¬¸ì, ê³µë°± ì œê±° í›„ ì†Œë¬¸ìë¡œ ë³€í™˜
        normalized = re.sub(r'[^\wê°€-í£]', '', title).lower()
        return normalized
    
    # ìœ ì‚¬ ì œëª© ì²´í¬ í•¨ìˆ˜ (70% ì´ìƒ ê²¹ì¹˜ë©´ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨)
    def is_duplicate(new_title, existing_titles):
        new_normalized = normalize_title(new_title)
        for existing in existing_titles:
            existing_normalized = normalize_title(existing)
            # ì§§ì€ ìª½ ê¸°ì¤€ìœ¼ë¡œ ê²¹ì¹˜ëŠ” ë¹„ìœ¨ ê³„ì‚°
            if len(new_normalized) == 0 or len(existing_normalized) == 0:
                continue
            # í•œìª½ì´ ë‹¤ë¥¸ ìª½ì— í¬í•¨ë˜ë©´ ì¤‘ë³µ
            if new_normalized in existing_normalized or existing_normalized in new_normalized:
                return True
            # ê³µí†µ ë¬¸ì ë¹„ìœ¨ë¡œ ìœ ì‚¬ë„ ì²´í¬
            common = set(new_normalized) & set(existing_normalized)
            shorter = min(len(new_normalized), len(existing_normalized))
            if len(common) / shorter > 0.7:
                return True
        return False
    
    news = {}

    # ...ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œëŠ” newsletter_prompt.pyì—ì„œ import...

    for category, keyword in categories.items():
        news_list = []
        collected_titles = []  # ì¤‘ë³µ ì²´í¬ìš© ì œëª© ë¦¬ìŠ¤íŠ¸

        # RSSì—ì„œ ëª¨ë“  ì•„ì´í…œ ìˆ˜ì§‘ (ë‚ ì§œ ì •ë³´ í¬í•¨)
        all_items_with_date = []

        try:
            # ëª¨ë“  ì¹´í…Œê³ ë¦¬ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ - ì—¬ëŸ¬ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•˜ì—¬ ë‹¤ì–‘í•œ ì½˜í…ì¸  ìˆ˜ì§‘
            keywords = keyword if isinstance(keyword, list) else [keyword]
            for kw in keywords:
                try:
                    encoded_keyword = urllib.parse.quote(kw)
                    url = f'https://news.google.com/rss/search?q={encoded_keyword}&hl=ko&gl=KR&ceid=KR:ko'
                    # timeoutì„ 3ì´ˆë¡œ ì¤„ì´ê³ , ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ ì‹œ í•´ë‹¹ í‚¤ì›Œë“œëŠ” ê±´ë„ˆëœ€
                    res = requests.get(url, headers=headers, timeout=3, verify=False)
                    soup = BeautifulSoup(res.text, 'xml')
                    items = soup.find_all('item')

                    for item in items:
                        title = item.find('title').get_text(strip=True) if item.find('title') else ''
                        link = item.find('link').get_text(strip=True) if item.find('link') else ''
                        source = item.find('source').get_text(strip=True) if item.find('source') else ''
                        pub_date_str = item.find('pubDate').get_text(strip=True) if item.find('pubDate') else ''

                        weeks_ago = get_week_ago(pub_date_str)
                        # í•™ìˆ ê¸°ê´€ í‚¤ì›Œë“œê°€ ì œëª©/ì†ŒìŠ¤ì— í¬í•¨ëœ ë‰´ìŠ¤ëŠ” 'í•™ìˆ ê¸°ê´€ AX Trend'ì—ì„œë§Œ ë³´ì—¬ì£¼ê³ , ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ì„œëŠ” ì œì™¸
                        if any(ts in source or ts in title for ts in trusted_academic_sources):
                            continue
                        if weeks_ago:
                            all_items_with_date.append({
                                'title': title,
                                'link': link,
                                'source': source,
                                'pub_date_str': pub_date_str,
                                'weeks_ago': weeks_ago
                            })
                except Exception as e:
                    # ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜, íƒ€ì„ì•„ì›ƒ ë“± ë°œìƒ ì‹œ í•´ë‹¹ í‚¤ì›Œë“œëŠ” ê±´ë„ˆëœ€
                    continue

            # pub_date_str ê¸°ì¤€ ìµœì‹ ìˆœ ì •ë ¬
            all_items_with_date.sort(key=lambda x: x['pub_date_str'], reverse=True)

            # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ ë‰´ìŠ¤ ë¨¼ì € ìˆ˜ì§‘ (5ê°œê¹Œì§€)
            for item in all_items_with_date:
                if len(news_list) >= 5:
                    break
                title = item['title']
                link = item['link']
                source = item['source']
                pub_date_str = item['pub_date_str']
                weeks_ago = item['weeks_ago']

                # ì¤‘ë³µ ì²´í¬
                if is_duplicate(title, collected_titles):
                    continue

                # ì‹ ë¢° ì–¸ë¡ ì‚¬ë§Œ í•„í„°ë§ (í•™ìˆ ê¸°ê´€ì€ AX Trendì—ë§Œ ì‚¬ìš©)
                is_trusted = any(ts in source or ts in title for ts in trusted_sources)
                if title and link and is_trusted:
                    # ë‚ ì§œ í‘œê¸° ë³´ì™„: weeks_agoê°€ Noneì´ì–´ë„ ë‚ ì§œëŠ” í•­ìƒ í‘œì‹œ
                    date_display_str = format_date_with_week(pub_date_str, weeks_ago)
                    if not date_display_str:
                        # pub_date_strì´ ìˆìœ¼ë©´ ë‚ ì§œë§Œì´ë¼ë„ í‘œì‹œ
                        try:
                            from email.utils import parsedate_to_datetime
                            pub_date = parsedate_to_datetime(pub_date_str)
                            if pub_date:
                                date_display_str = pub_date.strftime('%m/%d')
                        except:
                            pass
                    date_display = f" <span style='color:#3b82f6;font-size:0.8em;'>[{date_display_str}]</span>" if date_display_str else ''
                    news_list.append(f"<a href='{link}' target='_blank'>{title}</a> <span style='color:#888;font-size:0.85em;'>({source})</span>{date_display}")
                    collected_titles.append(title)

            # 5ê°œ ë¯¸ë§Œì´ë©´ ë¹„ì‹ ë¢° ì–¸ë¡ ì‚¬ ë‰´ìŠ¤ë¡œ ì±„ìš°ê¸°
            if len(news_list) < 5:
                for item in all_items_with_date:
                    if len(news_list) >= 5:
                        break
                    title = item['title']
                    link = item['link']
                    source = item['source']
                    pub_date_str = item['pub_date_str']
                    weeks_ago = item['weeks_ago']

                    # ì¤‘ë³µ ì²´í¬
                    if is_duplicate(title, collected_titles):
                        continue

                    if title and link:
                        # ë‚ ì§œ í‘œê¸° ë³´ì™„: weeks_agoê°€ Noneì´ì–´ë„ ë‚ ì§œëŠ” í•­ìƒ í‘œì‹œ
                        date_display_str = format_date_with_week(pub_date_str, weeks_ago)
                        if not date_display_str:
                            try:
                                from email.utils import parsedate_to_datetime
                                pub_date = parsedate_to_datetime(pub_date_str)
                                if pub_date:
                                    date_display_str = pub_date.strftime('%m/%d')
                            except:
                                pass
                        date_display = f" <span style='color:#3b82f6;font-size:0.8em;'>[{date_display_str}]</span>" if date_display_str else ''
                        news_list.append(f"<a href='{link}' target='_blank'>{title}</a> <span style='color:#888;font-size:0.85em;'>({source})</span>{date_display}")
                        collected_titles.append(title)

        except Exception as e:
            news_list.append(f'ìˆ˜ì§‘ ì˜¤ë¥˜: {e}')

        # ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€ ì¶”ê°€
        if not news_list:
            news_list.append('ìµœê·¼ 4ì£¼ê°„ ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.')

        news[category] = news_list


    # í•™ìˆ ê¸°ê´€ AX Trend ì¹´í…Œê³ ë¦¬: trusted_academic_sources í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ 5ê°œê¹Œì§€ ì¡°íšŒ
    academic_news_list = []
    collected_titles = []
    all_items_with_date = []
    try:
        # ì •ì¹˜, ì‚¬íšŒ, ì—°ì˜ˆ ë“± ë¹„í•™ìˆ ì  í‚¤ì›Œë“œ ëª©ë¡
        non_academic_keywords = [
            'ì •ì¹˜', 'ëŒ€í†µë ¹', 'ì´ë¦¬', 'êµ­íšŒ', 'ì˜ì›', 'ì„ ê±°', 'ì •ë‹¹', 'ì •ë¶€', 'ì²­ì™€ëŒ€',
            'ì‚¬íšŒ', 'ì‚¬ê±´', 'ì‚¬ê³ ', 'ë²”ì£„', 'ì¬íŒ', 'ë²•ì›', 'ê²€ì°°', 'ê²½ì°°',
            'ì—°ì˜ˆ', 'ì—°ì˜ˆì¸', 'ê°€ìˆ˜', 'ë°°ìš°', 'ë°©ì†¡', 'ë“œë¼ë§ˆ', 'ì˜í™”', 'ìŠ¤í¬ì¸ ',
            'ì‚¬ë§', 'ì‚¬ê±´ì‚¬ê³ ', 'ë…¼ë€', 'ì…í•™ì·¨ì†Œ', 'ì§•ê³„', 'ì •ì¹˜ê¶Œ', 'ì •ì¹˜ì¸', 'ë¶€ì •', 'ë¹„ë¦¬', 'ì˜í˜¹', 'ë…¼ë¬¸ í‘œì ˆ', 'ì…ì‹œ', 'ì…í•™', 'í‡´ì¶œ', 'ì§•ê³„', 'ìœ¤ë¦¬', 'ì¡°ë¯¼', 'ê¹€ê±´í¬'
        ]
        for kw in trusted_academic_sources:
            encoded_keyword = urllib.parse.quote(kw)
            url = f'https://news.google.com/rss/search?q={encoded_keyword}&hl=ko&gl=KR&ceid=KR:ko'
            res = requests.get(url, headers=headers, timeout=10, verify=False)
            soup = BeautifulSoup(res.text, 'xml')
            items = soup.find_all('item')
            for item in items:
                title = item.find('title').get_text(strip=True) if item.find('title') else ''
                link = item.find('link').get_text(strip=True) if item.find('link') else ''
                source = item.find('source').get_text(strip=True) if item.find('source') else ''
                pub_date_str = item.find('pubDate').get_text(strip=True) if item.find('pubDate') else ''
                weeks_ago = get_week_ago(pub_date_str)
                # ë¹„í•™ìˆ ì  í‚¤ì›Œë“œê°€ ì œëª©ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì œì™¸
                if any(bad_kw in title for bad_kw in non_academic_keywords):
                    continue
                if weeks_ago:
                    all_items_with_date.append({
                        'title': title,
                        'link': link,
                        'source': source,
                        'pub_date_str': pub_date_str,
                        'weeks_ago': weeks_ago
                    })
        # pub_date_str ê¸°ì¤€ ìµœì‹ ìˆœ ì •ë ¬
        all_items_with_date.sort(key=lambda x: x['pub_date_str'], reverse=True)
        for item in all_items_with_date:
            if len(academic_news_list) >= 5:
                break
            title = item['title']
            link = item['link']
            source = item['source']
            pub_date_str = item['pub_date_str']
            weeks_ago = item['weeks_ago']
            if is_duplicate(title, collected_titles):
                continue
            # ì‹ ë¢° í•™ìˆ ê¸°ê´€ í‚¤ì›Œë“œê°€ ì œëª© ë˜ëŠ” ì†ŒìŠ¤ì— í¬í•¨ëœ ê²½ìš°ë§Œ
            is_trusted_academic = any(ts in source or ts in title for ts in trusted_academic_sources)
            if title and link and is_trusted_academic:
                date_display_str = format_date_with_week(pub_date_str, weeks_ago)
                if not date_display_str:
                    try:
                        from email.utils import parsedate_to_datetime
                        pub_date = parsedate_to_datetime(pub_date_str)
                        if pub_date:
                            date_display_str = pub_date.strftime('%m/%d')
                    except:
                        pass
                date_display = f" <span style='color:#3b82f6;font-size:0.8em;'>[{date_display_str}]</span>" if date_display_str else ''
                academic_news_list.append(f"<a href='{link}' target='_blank'>{title}</a> <span style='color:#888;font-size:0.85em;'>({source})</span>{date_display}")
                collected_titles.append(title)
        if not academic_news_list:
            academic_news_list.append('ìµœê·¼ 4ì£¼ê°„ ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.')
    except Exception as e:
        academic_news_list.append(f'ìˆ˜ì§‘ ì˜¤ë¥˜: {e}')
    news['í•™ìˆ ê¸°ê´€ AX Trend'] = academic_news_list

    # ì¹´í…Œê³ ë¦¬ ìˆœì„œ ì¬ì •ë ¬: í•´ì™¸ AI ì‹ ê·œë‰´ìŠ¤ ë’¤ì— í•™ìˆ ê¸°ê´€ AX Trend, ê·¸ ë‹¤ìŒ í”¼ì§€ì»¬ AI
    ordered_keys = []
    for k in ['AX í™œìš© ì‚¬ë¡€', 'êµ­ë‚´ AI ì†Œì‹', 'í•´ì™¸ AI ì‹ ê·œë‰´ìŠ¤', 'í•™ìˆ ê¸°ê´€ AX Trend', 'í”¼ì§€ì»¬ AI', 'ê¸ˆìœµì‚¬ AI ì ìš© ì‚¬ë¡€ ë° ê·œì œ ì™„í™” ì†Œì‹', 'ğŸ”¥ í•œí™”ê·¸ë£¹ Hot News']:
        if k in news:
            ordered_keys.append(k)
    # ê¸°ì¡´ news ë”•ì…”ë„ˆë¦¬ì˜ ìˆœì„œ ë³´ì¥
    news = {k: news[k] for k in ordered_keys}

    return news
def collect_youtube_recommendations():
    # IT/AI í•™ìŠµ ëª©ì ì˜ ê±´ì „í•œ ì˜ìƒë§Œ ìˆ˜ì§‘ (ê³µê°œ ë°œí‘œìš©)
    # ì „ì£¼ ì›”ìš”ì¼~ì¼ìš”ì¼ ì‚¬ì´ ì˜ìƒ, ì¸ê¸°ìˆœ ì •ë ¬
    import urllib.parse
    import warnings
    import re
    from datetime import datetime, timedelta
    warnings.filterwarnings('ignore')
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    # ì „ì£¼ ì›”ìš”ì¼~ì¼ìš”ì¼ ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
    today = datetime.now()
    this_monday = today - timedelta(days=today.weekday())
    last_monday = this_monday - timedelta(days=7)
    last_sunday = last_monday + timedelta(days=6)
    
    print(f'ğŸ“º ìœ íŠœë¸Œ ìˆ˜ì§‘ ê¸°ê°„: {last_monday.strftime("%Y-%m-%d")} ~ {last_sunday.strftime("%Y-%m-%d")} (ì¸ê¸°ìˆœ)')
    
    # IT/AI ê´€ë ¨ í‚¤ì›Œë“œ í•„í„° (ì´ í‚¤ì›Œë“œê°€ ì œëª©ì— í¬í•¨ëœ ì˜ìƒë§Œ ì¶”ì²œ)
    it_ai_keywords = [
        'AI', 'ì¸ê³µì§€ëŠ¥', 'GPT', 'ChatGPT', 'ì±—GPT', 'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹',
        'ë°ì´í„°', 'ë¶„ì„', 'ìë™í™”', 'AX', 'DX', 'ë””ì§€í„¸', 'ì „í™˜',
        'ë¡œë´‡', 'í´ë¼ìš°ë“œ', 'ë¹…ë°ì´í„°', 'IT', 'RPA', 'ì½”ë”©', 'í”„ë¡œê·¸ë˜ë°',
        'ì•Œê³ ë¦¬ì¦˜', 'í…Œí¬', 'ê¸°ìˆ ', 'í˜ì‹ ', 'ìŠ¤ë§ˆíŠ¸', 'í”Œë«í¼',
        'ë¹„ì¦ˆë‹ˆìŠ¤', 'ì—…ë¬´', 'ìƒì‚°ì„±', 'íš¨ìœ¨', 'ì†”ë£¨ì…˜'
    ]
    
    youtube_list = []
    
    # IT/AI í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸ í•¨ìˆ˜
    def is_it_ai_content(title):
        title_lower = title.lower()
        for keyword in it_ai_keywords:
            if keyword.lower() in title_lower:
                return True
        return False
    
    # ë‚ ì§œê°€ ì „ì£¼ ë²”ìœ„ ë‚´ì¸ì§€ í™•ì¸
    def is_within_week(date_str):
        try:
            if not date_str:
                return False
            # YYYY-MM-DD í˜•ì‹
            pub_date = datetime.strptime(date_str[:10], '%Y-%m-%d')
            return last_monday.date() <= pub_date.date() <= last_sunday.date()
        except:
            return False
    
    # ë‚ ì§œ í¬ë§· í•¨ìˆ˜
    def format_date(date_str):
        try:
            if date_str:
                pub_date = datetime.strptime(date_str[:10], '%Y-%m-%d')
                return pub_date.strftime('%m/%d')
        except:
            pass
        return ''
    
    # ìœ íŠœë¸Œ ê²€ìƒ‰ í‚¤ì›Œë“œëŠ” newsletter_prompt.pyì—ì„œ import
    from newsletter_prompt import youtube_search_keywords
    
    for keyword in youtube_search_keywords:
        try:
            encoded_keyword = urllib.parse.quote(keyword)
            # YouTube ê²€ìƒ‰ - ì´ë²ˆ ì£¼ ì—…ë¡œë“œ + ì¡°íšŒìˆ˜ìˆœ ì •ë ¬
            # sp=CAMSBAgCEAE: ì´ë²ˆ ì£¼ + ì¡°íšŒìˆ˜ìˆœ
            # sp=EgQIBRAB: ì´ë²ˆ ì£¼ë§Œ
            url = f'https://www.youtube.com/results?search_query={encoded_keyword}&sp=EgQIBRAB'
            res = requests.get(url, headers=headers, timeout=10, verify=False)
            
            # YouTube í˜ì´ì§€ì—ì„œ videoIdì™€ viewCount ì¶”ì¶œ
            video_data = re.findall(r'"videoId":"([a-zA-Z0-9_-]{11})".*?"viewCountText":\{"simpleText":"ì¡°íšŒìˆ˜ ([0-9,]+)íšŒ"\}', res.text)
            
            # viewCountë¡œ ì •ë ¬ì´ ì•ˆë˜ë©´ ê¸°ë³¸ videoIdë§Œ ì¶”ì¶œ
            if not video_data:
                video_ids = re.findall(r'"videoId":"([a-zA-Z0-9_-]{11})"', res.text)
                video_data = [(vid, '0') for vid in video_ids[:5]]
            
            # ì¡°íšŒìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            video_data_sorted = sorted(video_data, key=lambda x: int(x[1].replace(',', '')) if x[1] else 0, reverse=True)
            
            for video_id, view_count in video_data_sorted[:3]:  # ìƒìœ„ 3ê°œë§Œ í™•ì¸
                try:
                    # oEmbed APIë¡œ ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    oembed_url = f'https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v={video_id}&format=json'
                    oembed_res = requests.get(oembed_url, timeout=5, verify=False)
                    
                    if oembed_res.status_code == 200:
                        oembed_data = oembed_res.json()
                        title = oembed_data.get('title', '')
                        channel = oembed_data.get('author_name', 'ìœ íŠœë¸Œ')
                        thumbnail = f'https://img.youtube.com/vi/{video_id}/mqdefault.jpg'
                        link = f'https://www.youtube.com/watch?v={video_id}'
                        
                        # IT/AI ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì˜ìƒë§Œ ì¶”ê°€
                        if title and is_it_ai_content(title):
                            # ì¤‘ë³µ ì²´í¬
                            if any(item['title'] == title for item in youtube_list):
                                continue
                            
                            # ì¡°íšŒìˆ˜ íŒŒì‹±
                            views = int(view_count.replace(',', '')) if view_count else 0
                            
                            youtube_list.append({
                                'channel': channel,
                                'title': title,
                                'link': link,
                                'thumbnail': thumbnail,
                                'date': '',  # ê²€ìƒ‰ ê²°ê³¼ì—ì„œëŠ” ë‚ ì§œ ì¶”ì¶œ ì–´ë ¤ì›€
                                'views': views
                            })
                            break  # í‚¤ì›Œë“œë‹¹ 1ê°œë§Œ
                except:
                    continue
        except:
            continue
    
    # ì¡°íšŒìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    youtube_list.sort(key=lambda x: x.get('views', 0), reverse=True)
    
    # ì¤‘ë³µ ì œê±° ë° ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
    seen_titles = set()
    unique_list = []
    for item in youtube_list:
        if item['title'] not in seen_titles:
            seen_titles.add(item['title'])
            unique_list.append(item)
    
    return unique_list[:5]  # ìµœëŒ€ 5ê°œë§Œ ë°˜í™˜

# 2. HTML ë³¸ë¬¸ ìƒì„± í•¨ìˆ˜
def generate_html(news, youtube_recommendations=None, email_version=True):
    """
    HTML ë‰´ìŠ¤ë ˆí„° ìƒì„±
    email_version=True: ì´ë©”ì¼ìš© (ë‹¨ìƒ‰ ë°°ê²½, í˜¸í™˜ì„± ìš°ì„ )
    email_version=False: ë¸Œë¼ìš°ì €ìš© (ê·¸ë¼ë°ì´ì…˜ ë°°ê²½, í’€ ë””ìì¸)
    """
    today = datetime.date.today().strftime('%Yë…„ %mì›” %dì¼')
    
    # ì´ë©”ì¼ ë²„ì „ê³¼ ë¸Œë¼ìš°ì € ë²„ì „ì˜ ë°°ê²½ ìŠ¤íƒ€ì¼ ë¶„ë¦¬
    if email_version:
        header_bg = 'background-color:#1e3a8a;'
        subheader_bg = 'background-color:#1e3a8a;'
        footer_bg = 'background-color:#1e3a8a;'
        banner_bg = 'background-color:#f7931e;'  # ì´ë©”ì¼ìš© ë‹¨ìƒ‰
    else:
        header_bg = 'background:linear-gradient(135deg, #1e3a8a 0%, #3b82f6 100%);'
        subheader_bg = 'background:linear-gradient(90deg, #1e3a8a 0%, #2563eb 100%);'
        footer_bg = 'background:linear-gradient(135deg, #1e3a8a 0%, #3b82f6 100%);'
        banner_bg = 'background:linear-gradient(90deg, #ff6b35 0%, #f7931e 100%);'  # ë¸Œë¼ìš°ì €ìš© ê·¸ë¼ë°ì´ì…˜
    
    html = f"""
    <style>
        .date-badge {{{{
            display: none !important;
        }}}}
        .content-cell {{{{
            padding: 15px !important;
        }}}}
        .section-title {{{{
            font-size: 1em !important;
        }}}}
        .news-item {{{{
            font-size: 14px !important;
        }}}}
        .youtube-thumb {{{{
            width: 120px !important;
            height: 68px !important;
        }}}}
        .youtube-title {{{{
            font-size: 13px !important;
        }}}}
        .footer-cell {{{{
            padding: 15px !important;
        }}}}
        .logo-badge {{{{
            padding: 8px 12px !important;
        }}}}
        .logo-text {{{{
            font-size: 14px !important;
        }}}}
    </style>
    </head>
    <body style='font-family:Segoe UI,Arial,sans-serif; background-color:#f5f5f5; margin:0; padding:10px; word-wrap:break-word; word-break:break-word;'>
        <!-- ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ë³´ê¸° ë°°ë„ˆ (Outlook í˜¸í™˜) -->
        <table width='100%' cellpadding='0' cellspacing='0' border='0' style='max-width:1000px; width:100%; margin:0 auto 15px auto;'>
            <tr>
                <td align='center' bgcolor='#f7931e' style='background-color:#f7931e; border-radius:12px; mso-padding-alt:15px 20px;'>
                    <a href='{{{{web_version_url}}}}' target='_blank' style='display:block; padding:15px 20px; color:#ffffff; font-family:Segoe UI,Arial,sans-serif; font-size:15px; font-weight:bold; text-decoration:none; text-align:center;'>
                        &#10024; ë” ë©‹ì§„ ë””ìì¸ìœ¼ë¡œ ë³´ê¸° - í´ë¦­í•˜ì—¬ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸° &#8594;
                    </a>
                </td>
            </tr>
        </table>
        <!-- ë‰´ìŠ¤ë ˆí„° í—¤ë” ë°°ë„ˆ -->
        <table class='email-container' width='100%' cellpadding='0' cellspacing='0' border='0' style='max-width:1000px; width:100%; margin:0 auto;'>
            <tr>
                <td class='header-cell' style='{header_bg} border-radius:16px 16px 0 0; padding:20px;'>
                    <!-- ë¡œê³  + ë‚ ì§œ í•œ ì¤„ -->
                    <table width='100%' cellpadding='0' cellspacing='0' border='0'>
                        <tr>
                            <td style='vertical-align:middle;'>
                                <div style='display:inline-block; background:#fff; border-radius:10px; padding:8px 12px;'>
                                    <span style='font-size:20px;'>ğŸš€</span>
                                    <span style='font-size:14px; font-weight:700; color:#1e3a8a;'>Hanwha Systems/ICT</span>
                                </div>
                            </td>
                            <td style='text-align:right; vertical-align:middle;'>
                                <span style='color:#fff; font-size:13px; background:rgba(255,255,255,0.2); padding:6px 12px; border-radius:8px;'>ğŸ“… {today}</span>
                            </td>
                        </tr>
                    </table>
                    <!-- ë©”ì¸ íƒ€ì´í‹€ -->
                    <h1 style='color:#ffffff; font-size:24px; font-weight:800; margin:15px 0 5px 0;'>
                        AX / IT íŠ¸ëœë“œ ë‰´ìŠ¤ë ˆí„°
                    </h1>
                    <p style='color:rgba(255,255,255,0.85); font-size:12px; margin:0;'>
                        AI Transformation & Digital Innovation Weekly Digest
                    </p>
                </td>
            </tr>
            <!-- ì„œë¸Œ í—¤ë” ë°” -->
            <tr>
                <td class='content-cell' style='{subheader_bg} padding:10px 25px;'>
                    <table width='100%' cellpadding='0' cellspacing='0' border='0'>
                        <tr>
                            <td class='header-subtitle' style='color:rgba(255,255,255,0.9); font-size:11px;'>
                                ğŸ“Š AX &nbsp;|&nbsp; ğŸ¤– AI &nbsp;|&nbsp; ğŸŒ ê¸€ë¡œë²Œ &nbsp;|&nbsp; ğŸ”¥ í•œí™”
                            </td>
                        </tr>
                    </table>
                </td>
            </tr>
            <!-- ë³¸ë¬¸ ì»¨í…Œì´ë„ˆ -->
            <tr>
                <td class='content-cell' style='background:#ffffff; padding:20px 25px;'>
    """
    # ì¹´í…Œê³ ë¦¬ë³„ ì•„ì´ì½˜ ë§¤í•‘
    section_icons = {
        'AX í™œìš© ì‚¬ë¡€': 'âš¡',
        'êµ­ë‚´ AI ì†Œì‹': 'ğŸ‡°ğŸ‡·',
        'í•´ì™¸ AI ì‹ ê·œë‰´ìŠ¤': 'ğŸŒ',
        'í”¼ì§€ì»¬ AI': 'ğŸ¤–',
        'ê¸ˆìœµì‚¬ AI ì ìš© ì‚¬ë¡€ ë° ê·œì œ ì™„í™” ì†Œì‹': 'ğŸ’°',
        'ğŸ”¥ í•œí™”ê·¸ë£¹ Hot News': 'ğŸ”¥'
    }
    
    for section, items in news.items():
        icon = section_icons.get(section, 'ğŸ“°')
        # í•œí™”ê·¸ë£¹ ë‰´ìŠ¤ëŠ” íŠ¹ë³„ ìŠ¤íƒ€ì¼
        if 'í•œí™”' in section:
            html += f"""
            <div style='background-color:#ff6b35; border-radius:12px; padding:20px; margin:25px 0 15px 0;'>
                <h2 class='section-title' style='color:#fff; margin:0; font-size:1.3em;'>{section}</h2>
            </div>
            <ul style='list-style:none; padding:0; margin:0;'>
            """
        else:
            html += f"""
            <div style='border-left:4px solid #3b82f6; padding-left:15px; margin:25px 0 15px 0;'>
                <h2 class='section-title' style='color:#1e3a8a; margin:0; font-size:1.2em;'>{icon} {section}</h2>
            </div>
            <ul style='list-style:none; padding:0; margin:0;'>
            """
        for item in items:
            html += f"<li class='news-item' style='padding:8px 0; border-bottom:1px solid #f0f0f0; word-wrap:break-word; word-break:break-word; overflow-wrap:break-word;'>{item}</li>"
        html += "</ul>"
    
    # ìœ íŠœë²„ ì¶”ì²œ ì„¹ì…˜ ì¶”ê°€ (ì¸ë„¤ì¼ Base64 ì¸ë¼ì¸ í¬í•¨)
    if youtube_recommendations:
        html += """
        <div style='margin-top:40px; padding:25px; background:#f8f9fa; border-radius:16px;'>
            <h2 style='color:#333; margin-top:0; margin-bottom:8px; font-size:1.4em;'>ğŸ¬ ì¶”ì²œ AX ì˜ìƒ</h2>
            <p style='color:#666; font-size:0.9em; margin-bottom:20px;'>ì´ë²ˆ ì£¼ ì£¼ëª©í•  ë§Œí•œ AI/AX ê´€ë ¨ ìœ íŠœë¸Œ ì½˜í…ì¸ ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.</p>
            <table cellpadding='0' cellspacing='0' border='0' width='100%'>
        """
        for idx, video in enumerate(youtube_recommendations, 1):
            date_str = video.get('date', '')
            thumbnail_url = video.get('thumbnail', '')
            
            # ì¸ë„¤ì¼ ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©
            thumbnail_base64 = ''
            if thumbnail_url:
                try:
                    import warnings
                    warnings.filterwarnings('ignore')
                    img_response = requests.get(thumbnail_url, timeout=5, verify=False)
                    if img_response.status_code == 200:
                        thumbnail_base64 = base64.b64encode(img_response.content).decode('utf-8')
                except:
                    pass
            
            # ì¸ë„¤ì¼ì´ ìˆìœ¼ë©´ ì´ë¯¸ì§€ í‘œì‹œ, ì—†ìœ¼ë©´ ëŒ€ì²´ ì•„ì´ì½˜
            if thumbnail_base64:
                img_html = f"<img class='youtube-thumb' src='data:image/jpeg;base64,{thumbnail_base64}' alt='ì¸ë„¤ì¼' style='width:160px; height:90px; object-fit:cover; border-radius:8px; display:block;'>"
            else:
                img_html = "<div class='youtube-thumb' style='width:160px; height:90px; background-color:#ff0000; border-radius:8px; display:table-cell; vertical-align:middle; text-align:center; color:#fff; font-size:32px;'>â–¶</div>"
            
            html += f"""
                <tr>
                    <td style='padding:10px 0; border-bottom:1px solid #eee;'>
                        <table cellpadding='0' cellspacing='0' border='0' width='100%'>
                            <tr>
                                <td width='170' valign='top'>
                                    <a href='{video['link']}' target='_blank'>{img_html}</a>
                                </td>
                                <td valign='top' style='padding-left:15px;'>
                                    <a class='youtube-title' href='{video['link']}' target='_blank' style='text-decoration:none; color:#222; font-size:0.95em; font-weight:600; line-height:1.4;'>{video['title']}</a>
                                    <div style='margin-top:8px;'>
                                        <span style='color:#ff0000; font-size:0.8em; font-weight:500;'>{video['channel']}</span>
                                    </div>
                                    <div style='color:#888; font-size:0.75em; margin-top:4px;'>{date_str}</div>
                                </td>
                            </tr>
                        </table>
                    </td>
                </tr>
            """
        html += """
            </table>
        </div>
        """
    
    html += f"""
                </td>
            </tr>
            <!-- í‘¸í„° -->
            <tr>
                <td class='footer-cell' style='{footer_bg} border-radius:0 0 16px 16px; padding:20px 25px;'>
                    <table width='100%' cellpadding='0' cellspacing='0' border='0'>
                        <tr>
                            <td style='color:#ffffff; font-size:11px; line-height:1.6; vertical-align:middle;'>
                                <div class='logo-badge' style='font-weight:600; font-size:13px; margin-bottom:8px;'>ğŸš€ Hanwha Systems/ICT</div>
                                ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤ì „ 8ì‹œ ìë™ ë°œì†¡<br>
                                AI/AX íŠ¸ëœë“œ & í•œí™”ê·¸ë£¹ ë‰´ìŠ¤
                            </td>
                            <td style='color:rgba(255,255,255,0.7); font-size:10px; text-align:right; vertical-align:middle;'>
                                Copyright 2026. hanwhasystem Inc. All rights reserved.
                            </td>
                        </tr>
                    </table>
                </td>
            </tr>
        </table>
    </body>
    </html>
    """
    return html

# 3. ì´ë©”ì¼ ë°œì†¡ í•¨ìˆ˜
def send_email(html):
    # Gmail SMTP ì„¤ì •
    smtp_server = 'smtp.gmail.com'
    smtp_port = 587
    
    # ì´ë©”ì¼ ì„¤ì • (ì•”í˜¸í™”ëœ config íŒŒì¼ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ìŒ)
    sender_email = get_config_value('SENDER_EMAIL')
    sender_password = get_config_value('EMAIL_PASSWORD')
    receiver_email = get_config_value('RECEIVER_EMAIL')

    # ë©”ì¼ ë©”ì‹œì§€ êµ¬ì„±
    msg = MIMEMultipart('alternative')
    # í•œê¸€ ì œëª©ì„ ìœ„í•œ Header ì ìš©
    msg['Subject'] = Header('AX / IT íŠ¸ëœë“œ ë‰´ìŠ¤ë ˆí„°', 'utf-8')
    # ë°œì‹ ì ì´ë¦„ ë° í‘œì‹œ ì´ë©”ì¼ ì„¤ì • (ì•”í˜¸í™”ëœ configì—ì„œ ì½ìŒ)
    sender_name = 'AX / IT Trend for U'
    display_email = get_config_value('DISPLAY_EMAIL')
    msg['From'] = f'{sender_name} <{display_email}>'
    msg['To'] = receiver_email
    # í•œê¸€ ì¸ì½”ë”© ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ charsetì„ utf-8ë¡œ ëª…ì‹œ
    msg.attach(MIMEText(html, 'html', 'utf-8'))

    # SMTP ì„œë²„ ì—°ê²° ë° ë©”ì¼ ë°œì†¡
    try:
        server = smtplib.SMTP(smtp_server, smtp_port)
        server.starttls()
        server.login(sender_email, sender_password)
        # í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ as_bytes()ë¡œ ì „ì†¡
        server.sendmail(sender_email, receiver_email, msg.as_bytes())
        server.quit()
        print('ë‰´ìŠ¤ë ˆí„° ë°œì†¡ ì™„ë£Œ!')
    except Exception as e:
        print('ë©”ì¼ ë°œì†¡ ì˜¤ë¥˜:', e)

if __name__ == '__main__':
    news = collect_news()
    # ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘ ê²°ê³¼ë¥¼ ì½˜ì†”ì— ì¶œë ¥
    for section, items in news.items():
        print(f'[{section}]')
        for item in items:
            print(item)
        print('-' * 40)

    # ìœ íŠœë¸Œ ì¶”ì²œ ì˜ìƒ ìˆ˜ì§‘
    print('[ìœ íŠœë¸Œ ì¶”ì²œ ì˜ìƒ]')
    youtube_recommendations = collect_youtube_recommendations()
    for video in youtube_recommendations:
        print(f"â–¶ {video['title']} ({video['channel']})")
        print(f"   ì¸ë„¤ì¼: {video.get('thumbnail', 'N/A')}")
    print('-' * 40)

    # ë¯¸ë¦¬ë³´ê¸°ìš© HTML íŒŒì¼ ê²½ë¡œ ì„¤ì • (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€)
    script_dir = os.path.dirname(os.path.abspath(__file__))
    preview_path = os.path.join(script_dir, 'newsletter_preview_auto.html')

    # 1. ë¸Œë¼ìš°ì € ë²„ì „ HTML ìƒì„± (ê·¸ë¼ë°ì´ì…˜ ì ìš©)
    html_browser = generate_html(news, youtube_recommendations, email_version=False)
    html_browser = html_browser.replace('{{web_version_url}}', preview_path)

    # ë¸Œë¼ìš°ì € ë²„ì „ HTML íŒŒì¼ë¡œ ë¡œì»¬ ì €ì¥
    with open(preview_path, 'w', encoding='utf-8') as f:
        f.write(html_browser)
    print(f'ë¸Œë¼ìš°ì € ë²„ì „ HTML ì €ì¥ ì™„ë£Œ: {preview_path}')

    # ì›¹ë¸Œë¼ìš°ì €ë¡œ ìë™ ì˜¤í”ˆ
    webbrowser.open('file://' + preview_path)

    # GitHub ì—…ë¡œë“œ ë° ì´ë©”ì¼ ë°œì†¡ì€ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ìƒëµ
    print('í…ŒìŠ¤íŠ¸: GitHub ì—…ë¡œë“œ ë° ì´ë©”ì¼ ë°œì†¡ ìƒëµ, HTMLë§Œ ìƒì„±/ì˜¤í”ˆ')
